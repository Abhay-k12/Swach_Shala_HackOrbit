{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6765,
     "status": "ok",
     "timestamp": 1751873494564,
     "user": {
      "displayName": "Abhay kanojia",
      "userId": "07946561113870187944"
     },
     "user_tz": -330
    },
    "id": "GNc7s8UOl69a",
    "outputId": "895b82d5-0585-49c1-f6e0-bfc0cf598a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# libraries that we're loading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras import layers, models, applications, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, save_img\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ci6Wx0dYtac3"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32727,
     "status": "ok",
     "timestamp": 1751873527295,
     "user": {
      "displayName": "Abhay kanojia",
      "userId": "07946561113870187944"
     },
     "user_tz": -330
    },
    "id": "YWxJR_1ttcgs",
    "outputId": "8841ca0c-0e4a-4447-926f-bfcdf8dd1185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image augmentation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define paths\n",
    "input_dir = '/content/drive/MyDrive/HackOrbit/Original_Images'\n",
    "output_dir = '/content/drive/MyDrive/HackOrbit/Original_Images_augmented'\n",
    "\n",
    "# Create output directories if not exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Number of augmented images per original\n",
    "num_augmented_images = 30\n",
    "\n",
    "# Loop through each category folder\n",
    "for category in os.listdir(input_dir):\n",
    "    category_path = os.path.join(input_dir, category)\n",
    "    if not os.path.isdir(category_path):\n",
    "        continue\n",
    "\n",
    "    save_category_path = os.path.join(output_dir, category)\n",
    "    if not os.path.exists(save_category_path):\n",
    "        os.makedirs(save_category_path)\n",
    "\n",
    "    # Loop through each image\n",
    "    for image_name in os.listdir(category_path):\n",
    "        image_path = os.path.join(category_path, image_name)\n",
    "        img = load_img(image_path)\n",
    "        x = img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        # Generate augmented images\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1,\n",
    "                                  save_to_dir=save_category_path,\n",
    "                                  save_prefix='aug',\n",
    "                                  save_format='jpeg'):\n",
    "            i += 1\n",
    "            if i >= num_augmented_images:\n",
    "                break\n",
    "\n",
    "print(\"Image augmentation completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1751873527299,
     "user": {
      "displayName": "Abhay kanojia",
      "userId": "07946561113870187944"
     },
     "user_tz": -330
    },
    "id": "HZWmnALHmZk7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Loading the data and processing it so that we can transfer it into the model\n",
    "root_dir = \"/content/drive/MyDrive/HackOrbit/Original_Images_augmented\"\n",
    "classification_names = [\"DirtyFloor\", \"OverflowingDustbins\", \"TrashPresence\", \"WaterLeaks\"]\n",
    "\n",
    "# Function to convert the images into vectorize form and provide them label\n",
    "def load_images_and_labels(root_dir, classification_names, img_size=(224,224)):\n",
    "    # Creating an empty list to store the images and their corresponding labels\n",
    "    data = []\n",
    "\n",
    "    # Loading the images from each folder present into the brain folder\n",
    "    for i, classification_name in enumerate(classification_names):\n",
    "        # full path to the disease folder\n",
    "        classification_path = os.path.join(root_dir, classification_name)\n",
    "\n",
    "        # loading image files in the current disease folder\n",
    "        image_files = os.listdir(classification_path)\n",
    "\n",
    "        # getting each image file in the current folder\n",
    "        for image_file in image_files:\n",
    "\n",
    "            # Checking image\n",
    "            if image_file.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "                # full path to the image file\n",
    "                image_path = os.path.join(classification_path, image_file)\n",
    "\n",
    "                # Loading the image using OpenCV\n",
    "                img = cv2.imread(image_path)\n",
    "                if img is None:\n",
    "                    print(f\"Warning: Could not read image: {image_path}\")\n",
    "                    continue    # Skip to the next image if loading fails\n",
    "\n",
    "                # resizing the image to a consistent size and converting into the grayscale image\n",
    "                img = cv2.resize(img, img_size)\n",
    "                label = i\n",
    "                data.append((img, label))\n",
    "\n",
    "    print(f\"Total images loaded: {len(data)}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1751873527302,
     "user": {
      "displayName": "Abhay kanojia",
      "userId": "07946561113870187944"
     },
     "user_tz": -330
    },
    "id": "AooCp4xJntzZ"
   },
   "outputs": [],
   "source": [
    "# function to apply remove_noise and split the initial corpus into vectors of image and labels\n",
    "def preprocess_data(data):\n",
    "    corpus = []\n",
    "    labels = []\n",
    "    for img, label in data:\n",
    "        # appending the denoised image to the new corpus\n",
    "        corpus.append(img)\n",
    "        labels.append(label)\n",
    "    return np.array(corpus), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1751873527305,
     "user": {
      "displayName": "Abhay kanojia",
      "userId": "07946561113870187944"
     },
     "user_tz": -330
    },
    "id": "z6ZLaRc1n4bc"
   },
   "outputs": [],
   "source": [
    "# Function to prepare the dataset for training the model\n",
    "def prepare_dataset(images, labels, batch_size=32, shuffle=True):\n",
    "    # normalizing the images and expand dims for channel\n",
    "    images = images.astype('float32') / 255.0\n",
    "    images = np.expand_dims(images, axis=-1)\n",
    "    labels = to_categorical(labels, num_classes=len(classification_names))\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1751873527318,
     "user": {
      "displayName": "Abhay kanojia",
      "userId": "07946561113870187944"
     },
     "user_tz": -330
    },
    "id": "ElDEw9_UABZq"
   },
   "outputs": [],
   "source": [
    "class ClassifierOptimized:\n",
    "    # constructor to initalise the values\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    # function to buil the model\n",
    "    def build_cnn(self):\n",
    "        inputs = layers.Input(shape=self.input_shape)\n",
    "        x = layers.Conv2D(32, (7, 7), padding='same')(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        # adjust the residual connection to match the number of filters\n",
    "        residual = layers.Conv2D(64, (1, 1), padding='same')(x)  # Matching the filter size\n",
    "        residual = layers.BatchNormalization()(residual)\n",
    "\n",
    "        x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.add([x, residual])  # Adding the residual connection\n",
    "\n",
    "        se = layers.GlobalAveragePooling2D()(x)\n",
    "        se = layers.Dense(64 // 16, activation='relu')(se)\n",
    "        se = layers.Dense(64, activation='sigmoid')(se)\n",
    "        se = layers.Reshape((1, 1, 64))(se)\n",
    "        x = layers.multiply([x, se])\n",
    "\n",
    "        x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(256, activation='relu')(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "\n",
    "        outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
    "\n",
    "        # compliling the model together with the inputs and outputs layers\n",
    "        model = models.Model(inputs, outputs)\n",
    "        model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy', tf.keras.metrics.AUC(name='auc')],\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8561,
     "status": "ok",
     "timestamp": 1751873535881,
     "user": {
      "displayName": "Abhay kanojia",
      "userId": "07946561113870187944"
     },
     "user_tz": -330
    },
    "id": "6df6A0R2oJGe",
    "outputId": "c8eb3b51-c436-4c69-a23b-844c79909635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images loaded: 1270\n"
     ]
    }
   ],
   "source": [
    "# loading and preprocess data\n",
    "data = load_images_and_labels(root_dir, classification_names)\n",
    "images, labels = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1751874870498,
     "user": {
      "displayName": "Abhay kanojia",
      "userId": "07946561113870187944"
     },
     "user_tz": -330
    },
    "id": "JNtk4WXxoULQ"
   },
   "outputs": [],
   "source": [
    "# dividing the data into train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.1, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1751874870972,
     "user": {
      "displayName": "Abhay kanojia",
      "userId": "07946561113870187944"
     },
     "user_tz": -330
    },
    "id": "FKi6OhQIypMX",
    "outputId": "9b9ca752-7e62-41cc-d92b-96a6f477460d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1143, 224, 224, 3), (127, 224, 224, 3))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 1635,
     "status": "ok",
     "timestamp": 1751874873766,
     "user": {
      "displayName": "Abhay kanojia",
      "userId": "07946561113870187944"
     },
     "user_tz": -330
    },
    "id": "2LyiqFgApA5Z"
   },
   "outputs": [],
   "source": [
    "# preapring the dataset\n",
    "batch_size = 32\n",
    "train_ds = prepare_dataset(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "test_ds = prepare_dataset(X_test, y_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1751874873786,
     "user": {
      "displayName": "Abhay kanojia",
      "userId": "07946561113870187944"
     },
     "user_tz": -330
    },
    "id": "kfVWWY7GpE03"
   },
   "outputs": [],
   "source": [
    "\n",
    "# building the model\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = len(classification_names)\n",
    "classifier = ClassifierOptimized(input_shape, num_classes)\n",
    "model = classifier.build_cnn()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 139434,
     "status": "ok",
     "timestamp": 1751875014838,
     "user": {
      "displayName": "Abhay kanojia",
      "userId": "07946561113870187944"
     },
     "user_tz": -330
    },
    "id": "3zYhmge1pYD1",
    "outputId": "e59d9d87-a2d6-47d8-826e-d1c784eaee6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 281ms/step - accuracy: 0.3858 - auc: 0.6268 - loss: 1.3250 - val_accuracy: 0.2598 - val_auc: 0.5545 - val_loss: 1.3786\n",
      "Epoch 2/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.6212 - auc: 0.8685 - loss: 0.9673 - val_accuracy: 0.2598 - val_auc: 0.5744 - val_loss: 1.4100\n",
      "Epoch 3/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.7162 - auc: 0.9173 - loss: 0.7982 - val_accuracy: 0.2598 - val_auc: 0.6116 - val_loss: 1.5810\n",
      "Epoch 4/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.7506 - auc: 0.9342 - loss: 0.7005 - val_accuracy: 0.2598 - val_auc: 0.6289 - val_loss: 1.9306\n",
      "Epoch 5/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.8082 - auc: 0.9591 - loss: 0.5859 - val_accuracy: 0.2598 - val_auc: 0.6103 - val_loss: 2.4044\n",
      "Epoch 6/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.8217 - auc: 0.9672 - loss: 0.5353 - val_accuracy: 0.2598 - val_auc: 0.6003 - val_loss: 2.8690\n",
      "Epoch 7/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - accuracy: 0.8583 - auc: 0.9749 - loss: 0.4668 - val_accuracy: 0.2598 - val_auc: 0.5737 - val_loss: 3.1809\n",
      "Epoch 8/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.8749 - auc: 0.9791 - loss: 0.4266 - val_accuracy: 0.2598 - val_auc: 0.5565 - val_loss: 3.5844\n",
      "Epoch 9/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.8736 - auc: 0.9780 - loss: 0.4180 - val_accuracy: 0.2598 - val_auc: 0.5648 - val_loss: 3.3053\n",
      "Epoch 10/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.8871 - auc: 0.9857 - loss: 0.3502 - val_accuracy: 0.2598 - val_auc: 0.5833 - val_loss: 3.2260\n",
      "Epoch 11/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.8784 - auc: 0.9842 - loss: 0.3488 - val_accuracy: 0.3622 - val_auc: 0.6433 - val_loss: 2.5942\n",
      "Epoch 12/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.9032 - auc: 0.9844 - loss: 0.3386 - val_accuracy: 0.2677 - val_auc: 0.6409 - val_loss: 2.5880\n",
      "Epoch 13/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.9051 - auc: 0.9883 - loss: 0.2944 - val_accuracy: 0.3228 - val_auc: 0.6261 - val_loss: 2.8645\n",
      "Epoch 14/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.9202 - auc: 0.9910 - loss: 0.2683 - val_accuracy: 0.4409 - val_auc: 0.7676 - val_loss: 1.4667\n",
      "Epoch 15/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.9148 - auc: 0.9896 - loss: 0.2800 - val_accuracy: 0.3858 - val_auc: 0.7956 - val_loss: 1.4418\n",
      "Epoch 16/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - accuracy: 0.9439 - auc: 0.9960 - loss: 0.2159 - val_accuracy: 0.5748 - val_auc: 0.8451 - val_loss: 1.0939\n",
      "Epoch 17/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9343 - auc: 0.9931 - loss: 0.2306 - val_accuracy: 0.7559 - val_auc: 0.9435 - val_loss: 0.5723\n",
      "Epoch 18/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.9493 - auc: 0.9954 - loss: 0.1975 - val_accuracy: 0.9291 - val_auc: 0.9942 - val_loss: 0.2644\n",
      "Epoch 19/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.9314 - auc: 0.9954 - loss: 0.2006 - val_accuracy: 0.8661 - val_auc: 0.9748 - val_loss: 0.3813\n",
      "Epoch 20/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9480 - auc: 0.9970 - loss: 0.1764 - val_accuracy: 0.8661 - val_auc: 0.9832 - val_loss: 0.3202\n",
      "Epoch 21/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.9592 - auc: 0.9977 - loss: 0.1524 - val_accuracy: 0.9843 - val_auc: 0.9997 - val_loss: 0.1608\n",
      "Epoch 22/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.9553 - auc: 0.9979 - loss: 0.1572 - val_accuracy: 0.8898 - val_auc: 0.9880 - val_loss: 0.2602\n",
      "Epoch 23/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.9514 - auc: 0.9975 - loss: 0.1595 - val_accuracy: 0.4961 - val_auc: 0.8086 - val_loss: 1.5547\n",
      "Epoch 24/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.9544 - auc: 0.9979 - loss: 0.1479 - val_accuracy: 0.7087 - val_auc: 0.9266 - val_loss: 0.6905\n",
      "Epoch 25/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.9733 - auc: 0.9983 - loss: 0.1330 - val_accuracy: 0.8661 - val_auc: 0.9856 - val_loss: 0.2816\n",
      "Epoch 26/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.9699 - auc: 0.9985 - loss: 0.1231 - val_accuracy: 0.8189 - val_auc: 0.9603 - val_loss: 0.5045\n",
      "Epoch 27/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.9737 - auc: 0.9987 - loss: 0.1208 - val_accuracy: 0.7874 - val_auc: 0.9524 - val_loss: 0.5074\n",
      "Epoch 28/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.9703 - auc: 0.9987 - loss: 0.1180 - val_accuracy: 0.9134 - val_auc: 0.9940 - val_loss: 0.2106\n",
      "Epoch 29/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.9718 - auc: 0.9990 - loss: 0.1089 - val_accuracy: 0.9528 - val_auc: 0.9978 - val_loss: 0.1339\n",
      "Epoch 30/30\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.9805 - auc: 0.9991 - loss: 0.0920 - val_accuracy: 0.9528 - val_auc: 0.9975 - val_loss: 0.1451\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9624 - auc: 0.9981 - loss: 0.1310\n",
      "Test Loss: 0.1451, Test Accuracy: 0.9528, Test AUC: 0.9975\n"
     ]
    }
   ],
   "source": [
    "# training model\n",
    "history = model.fit(train_ds, epochs=30, validation_data=test_ds)\n",
    "\n",
    "# evaluateing the model\n",
    "loss, accuracy, auc = model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}, Test AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1751875224784,
     "user": {
      "displayName": "Abhay kanojia",
      "userId": "07946561113870187944"
     },
     "user_tz": -330
    },
    "id": "AMs7jwq_pbHC"
   },
   "outputs": [],
   "source": [
    "# saving the model so taht we can use it to use in backend\n",
    "model.save('/content/drive/MyDrive/HackOrbit/hackrbitmodel.keras') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUxIXyqS5oIm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMx+BwaBa24UrdbTLShuYWc",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
